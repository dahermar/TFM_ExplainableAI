# TFM_ExplainableAI

Durante las últimas décadas, el campo de la Inteligencia Artificial ha crecido en popularidad. Las mejoras en las técnicas y la capacidad de cómputo han atraído a mucho público al mundo de la IA. Mientras que hace unas décadas el uso de la Inteligencia Artificial se veía limitado a aplicaciones puntuales, hoy en día estamos rodeados de sistemas que la utilizan como un pilar fundamental en su funcionamiento. Desde asistentes virtuales, recomendadores de películas en las diferentes plataformas de streaming, personalizadores de contenido en las redes sociales, filtros de spam en el correo, etc. gran cantidad de sistemas basan su funcionamiento en métodos de Inteligencia Artificial sin que muchas veces no seamos conscientes de ello.

Uno de los escenarios en los que más se ha expandido el uso de la IA es el mundo laboral. Muchas empresas han incluido a la Inteligencia Artificial como uno de los pilares fundamentales en su funcionamiento. El uso de la IA permite optimizar enormemente la realización de ciertas tareas, reduciendo considerablemente la cantidad de tiempo invertido por los trabajadores. Ejemplos de esto son la utilización de chat bots para atención al cliente o la creación de procesos para la preselección de personas que aplican a un puesto de trabajo. Además, la IA permite realizar tareas muy complejas que serían imposibles o extremadamente difíciles de ser completadas por un humano. Esto incluye análisis de volúmenes de datos masivos, simulaciones de escenarios estratégicos complejos o detección de patrones para mejorar el flujo de trabajo de la empresa. Es debido a la proliferación de la Inteligencia Artificial en el mundo laborar que surgió la motivación para realizar este trabajo. Tras varios años realizando multitud de modelos de Inteligencia Artificial con un fin académico, tenía el interés en poder realizar un modelo que tuviese una aplicación real. Debido a ello, decidí realizar un trabajo cuyo modelo final pudiese ser utilizado por una empresa en una aplicación real. Es aquí donde apareció el objetivo del proyecto, realizar un modelo de aprendizaje automático capaz de obtener información estratégica útil a partir de un conjunto de datos sobre incidencias IT de la empresa Bosch.

Pero una vez entramos en aplicaciones reales complejas nos encontramos con un problema. Gran parte de las veces, poder entender las decisiones que toma un algoritmo de aprendizaje automático es crucial a la hora de utilizar un modelo en un escenario real. Si no conocemos el motivo de las decisiones tomadas por un modelo, debemos depositar fe ciega en él a la hora de utilizar sus resultados. Pero, y si el algoritmo falla, ¿cómo podemos justificar sus decisiones o encontrar una solución si no somos capaces de entender por qué ha sucedido? Debido a ello, poder comprender los motivos que hacen al modelo tomar sus decisiones es crucial en escenarios donde los resultados del modelo tengan gran impacto. Debido a esto, podemos encontrarnos con un gran problema. Generalmente, los algoritmos y métodos más complejos utilizan procesos internos que no nos permiten comprender sus decisiones. Utilizar algoritmos más simples que nos permitan entender los procesos que sigue el modelo para tomar las decisiones puede ser una opción, aunque muchas veces no es viable, ya que nos podemos encontrar con escenarios complejos que no puedan ser resueltos con estos modelos más sencillos. Es aquí donde entra el concepto de Inteligencia Artificial explicable (XAI), la cual engloba a un conjunto de técnicas que nos permiten entender las decisiones tomadas por los algoritmos. Debido a ello, la utilización de estas técnicas en modelos complejos nos permite comprender sus decisiones, permitiéndonos utilizarlos en los escenarios donde esto sea una necesidad. La gran ventaja que ofrece la utilización de la IA explicable fue la principal motivación para incluirla en el proyecto. De esta forma, sería capaz de comprender las decisiones tomadas por los modelos implementados sobre los datos de las incidencias internas de Bosch.
